{
  "source": "0332_Stickynote_Send_Triggered.json",
  "index": 1,
  "content": "{\n  \"meta\": {\n    \"instanceId\": \"408f9fb9940c3cb18ffdef0e0150fe342d6e655c3a9fac21f0f644e8bedabcd9\",\n    \"templateCredsSetupCompleted\": true\n  },\n  \"nodes\": [\n    {\n      \"id\": \"27e5f0c0-ba88-4c28-b3be-99c973be15cb\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -480,\n        -140\n      ],\n      \"parameters\": {\n        \"width\": 1083,\n        \"height\": 357,\n        \"content\": \"## This is an example of basic LLM Chain connected to an open-source model\\n### The Chain is connected to the Mistral-7B-Instruct-v0.1 model, but you can change this\\n\\nPlease note the initial prompt that guides the model:\\n```\\nYou are a helpful assistant.\\nPlease reply politely to the users.\\nUse emojis and a text.\\nQ: {{ $json.input }}\\nA: \\n```\\n\\nThis way the model \\\"knows\\\" that it needs to answer the question right after the `A: `.\\n\\nSince Hugging Face node is this is an inference mode, it does not support LangChain Agents at the moment. Please use [Ollama Chat Model](https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/) node for that\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"4756d5a8-7027-4942-b214-a5ff8310869a\",\n      \"name\": \"When chat message received\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chatTrigger\",\n      \"position\": [\n        -200,\n        280\n      ],\n      \"webhookId\": \"bf2e38b8-566a-4aeb-8efe-28240f4a6991\",\n      \"parameters\": {\n        \"options\": {}\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"20a36351-8579-4ac6-9746-526b072aeaa6\",\n      \"name\": \"Basic LLM Chain\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chainLlm\",\n      \"position\": [\n        20,\n        280\n      ],\n      \"parameters\": {\n        \"messages\": {\n          \"messageValues\": [\n            {\n              \"message\": \"=You are a helpful assistant. Please reply politely to the users. Use emojis and a text.\"\n            }\n          ]\n        }\n      },\n      \"typeVersion\": 1.5\n    },\n    {\n      \"id\": \"9b88e307-3ad5-4167-8c5f-e5827f7444ac\",\n      \"name\": \"Hugging Face Inference Model\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmOpenHuggingFaceInference\",\n      \"position\": [\n        120,\n        440\n      ],\n      \"parameters\": {\n        \"model\": \"mistralai/Mistral-7B-Instruct-v0.1\",\n        \"options\": {\n          \"maxTokens\": 512,\n          \"temperature\": 0.8,\n          \"frequencyPenalty\": 2\n        }\n      },\n      \"credentials\": {\n        \"huggingFaceApi\": {\n          \"id\": \"ARQ5mOhvBxi283Qk\",\n          \"name\": \"HuggingFaceApi account\"\n        }\n      },\n      \"typeVersion\": 1\n    }\n  ],\n  \"pinData\": {},\n  \"connections\": {\n    \"When chat message received\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Basic LLM Chain\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Hugging Face Inference Model\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Basic LLM Chain\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}",
  "metadata": {
    "node_types": [
      "n8n-nodes-base.stickyNote",
      "@n8n/n8n-nodes-langchain.chatTrigger",
      "@n8n/n8n-nodes-langchain.chainLlm",
      "@n8n/n8n-nodes-langchain.lmOpenHuggingFaceInference"
    ],
    "trigger": null
  }
}