{
  "source": "1486_Noop_Stickynote_Automation_Triggered.json",
  "index": 1,
  "content": "{\n  \"id\": \"HMoUOg8J7RzEcslH\",\n  \"meta\": {\n    \"instanceId\": \"3f91626b10fcfa8a3d3ab8655534ff3e94151838fd2709ecd2dcb14afb3d061a\",\n    \"templateCredsSetupCompleted\": true\n  },\n  \"name\": \"Extract personal data with a self-hosted LLM Mistral NeMo\",\n  \"tags\": [],\n  \"nodes\": [\n    {\n      \"id\": \"7e67ae65-88aa-4e48-aa63-2d3a4208cf4b\",\n      \"name\": \"When chat message received\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chatTrigger\",\n      \"position\": [\n        -500,\n        20\n      ],\n      \"webhookId\": \"3a7b0ea1-47f3-4a94-8ff2-f5e1f3d9dc32\",\n      \"parameters\": {\n        \"options\": {}\n      },\n      \"typeVersion\": 1.1\n    },\n    {\n      \"id\": \"e064921c-69e6-4cfe-a86e-4e3aa3a5314a\",\n      \"name\": \"Ollama Chat Model\",\n      \"type\": \"@n8n/n8n-nodes-langchain.lmChatOllama\",\n      \"position\": [\n        -280,\n        420\n      ],\n      \"parameters\": {\n        \"model\": \"mistral-nemo:latest\",\n        \"options\": {\n          \"useMLock\": true,\n          \"keepAlive\": \"2h\",\n          \"temperature\": 0.1\n        }\n      },\n      \"credentials\": {\n        \"ollamaApi\": {\n          \"id\": \"vgKP7LGys9TXZ0KK\",\n          \"name\": \"Ollama account\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"fe1379da-a12e-4051-af91-9d67a7c9a76b\",\n      \"name\": \"Auto-fixing Output Parser\",\n      \"type\": \"@n8n/n8n-nodes-langchain.outputParserAutofixing\",\n      \"position\": [\n        -200,\n        220\n      ],\n      \"parameters\": {\n        \"options\": {\n          \"prompt\": \"Instructions:\\n--------------\\n{instructions}\\n--------------\\nCompletion:\\n--------------\\n{completion}\\n--------------\\n\\nAbove, the Completion did not satisfy the constraints given in the Instructions.\\nError:\\n--------------\\n{error}\\n--------------\\n\\nPlease try again. Please only respond with an answer that satisfies the constraints laid out in the Instructions:\"\n        }\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"b6633b00-6ebb-43ca-8e5c-664a53548c17\",\n      \"name\": \"Structured Output Parser\",\n      \"type\": \"@n8n/n8n-nodes-langchain.outputParserStructured\",\n      \"position\": [\n        60,\n        400\n      ],\n      \"parameters\": {\n        \"schemaType\": \"manual\",\n        \"inputSchema\": \"{\\n  \\\"type\\\": \\\"object\\\",\\n  \\\"properties\\\": {\\n    \\\"name\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Name of the user\\\"\\n    },\\n    \\\"surname\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Surname of the user\\\"\\n    },\\n    \\\"commtype\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"enum\\\": [\\\"email\\\", \\\"phone\\\", \\\"other\\\"],\\n      \\\"description\\\": \\\"Method of communication\\\"\\n    },\\n    \\\"contacts\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Contact details. ONLY IF PROVIDED\\\"\\n    },\\n    \\\"timestamp\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"format\\\": \\\"date-time\\\",\\n      \\\"description\\\": \\\"When the communication occurred\\\"\\n    },\\n    \\\"subject\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"description\\\": \\\"Brief description of the communication topic\\\"\\n    }\\n  },\\n  \\\"required\\\": [\\\"name\\\", \\\"commtype\\\"]\\n}\"\n      },\n      \"typeVersion\": 1.2\n    },\n    {\n      \"id\": \"23681a6c-cf62-48cb-86ee-08d5ce39bc0a\",\n      \"name\": \"Basic LLM Chain\",\n      \"type\": \"@n8n/n8n-nodes-langchain.chainLlm\",\n      \"onError\": \"continueErrorOutput\",\n      \"position\": [\n        -240,\n        20\n      ],\n      \"parameters\": {\n        \"messages\": {\n          \"messageValues\": [\n            {\n              \"message\": \"=Please analyse the incoming user request. Extract information according to the JSON schema. Today is: \\\"{{ $now.toISO() }}\\\"\"\n            }\n          ]\n        },\n        \"hasOutputParser\": true\n      },\n      \"typeVersion\": 1.5\n    },\n    {\n      \"id\": \"8f4d1b4b-58c0-41ec-9636-ac555e440821\",\n      \"name\": \"On Error\",\n      \"type\": \"n8n-nodes-base.noOp\",\n      \"position\": [\n        200,\n        140\n      ],\n      \"parameters\": {},\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"f4d77736-4470-48b4-8f61-149e09b70e3e\",\n      \"name\": \"Sticky Note\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -560,\n        -160\n      ],\n      \"parameters\": {\n        \"color\": 2,\n        \"width\": 960,\n        \"height\": 500,\n        \"content\": \"## Update data source\\nWhen you change the data source, remember to update the `Prompt Source (User Message)` setting in the **Basic LLM Chain node**.\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"5fd273c8-e61d-452b-8eac-8ac4b7fff6c2\",\n      \"name\": \"Sticky Note1\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -560,\n        340\n      ],\n      \"parameters\": {\n        \"color\": 2,\n        \"width\": 440,\n        \"height\": 220,\n        \"content\": \"## Configure local LLM\\nOllama offers additional settings \\nto optimize model performance\\nor memory usage.\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"63cbf762-0134-48da-a6cd-0363e870decd\",\n      \"name\": \"Sticky Note2\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        0,\n        340\n      ],\n      \"parameters\": {\n        \"color\": 2,\n        \"width\": 400,\n        \"height\": 220,\n        \"content\": \"## Define JSON Schema\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"9625294f-3cb4-4465-9dae-9976e0cf5053\",\n      \"name\": \"Extract JSON Output\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"position\": [\n        200,\n        -80\n      ],\n      \"parameters\": {\n        \"mode\": \"raw\",\n        \"options\": {},\n        \"jsonOutput\": \"={{ $json.output }}\\n\"\n      },\n      \"typeVersion\": 3.4\n    },\n    {\n      \"id\": \"2c6fba3b-0ffe-4112-b904-823f52cc220b\",\n      \"name\": \"Sticky Note3\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -560,\n        200\n      ],\n      \"parameters\": {\n        \"width\": 960,\n        \"height\": 120,\n        \"content\": \"If the LLM response does not pass \\nthe **Structured Output Parser** checks,\\n**Auto-Fixer** will call the model again with a different \\nprompt to correct the original response.\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"c73ba1ca-d727-4904-a5fd-01dd921a4738\",\n      \"name\": \"Sticky Note6\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        -560,\n        460\n      ],\n      \"parameters\": {\n        \"height\": 80,\n        \"content\": \"The same LLM connects to both **Basic LLM Chain** and to the **Auto-fixing Output Parser**. \\n\"\n      },\n      \"typeVersion\": 1\n    },\n    {\n      \"id\": \"193dd153-8511-4326-aaae-47b89d0cd049\",\n      \"name\": \"Sticky Note7\",\n      \"type\": \"n8n-nodes-base.stickyNote\",\n      \"position\": [\n        200,\n        440\n      ],\n      \"parameters\": {\n        \"width\": 200,\n        \"height\": 100,\n        \"content\": \"When the LLM model responds, the output is checked in the **Structured Output Parser**\"\n      },\n      \"typeVersion\": 1\n    }\n  ],\n  \"active\": false,\n  \"pinData\": {},\n  \"settings\": {\n    \"executionOrder\": \"v1\"\n  },\n  \"versionId\": \"9f3721a8-f340-43d5-89e7-3175c29c2f3a\",\n  \"connections\": {\n    \"Basic LLM Chain\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Extract JSON Output\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ],\n        [\n          {\n            \"node\": \"On Error\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Ollama Chat Model\": {\n      \"ai_languageModel\": [\n        [\n          {\n            \"node\": \"Auto-fixing Output Parser\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Basic LLM Chain\",\n            \"type\": \"ai_languageModel\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Structured Output Parser\": {\n      \"ai_outputParser\": [\n        [\n          {\n            \"node\": \"Auto-fixing Output Parser\",\n            \"type\": \"ai_outputParser\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Auto-fixing Output Parser\": {\n      \"ai_outputParser\": [\n        [\n          {\n            \"node\": \"Basic LLM Chain\",\n            \"type\": \"ai_outputParser\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"When chat message received\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Basic LLM Chain\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  }\n}",
  "metadata": {
    "node_types": [
      "@n8n/n8n-nodes-langchain.chatTrigger",
      "@n8n/n8n-nodes-langchain.lmChatOllama",
      "@n8n/n8n-nodes-langchain.outputParserAutofixing",
      "@n8n/n8n-nodes-langchain.outputParserStructured",
      "@n8n/n8n-nodes-langchain.chainLlm",
      "n8n-nodes-base.noOp",
      "n8n-nodes-base.stickyNote",
      "n8n-nodes-base.stickyNote",
      "n8n-nodes-base.stickyNote",
      "n8n-nodes-base.set",
      "n8n-nodes-base.stickyNote",
      "n8n-nodes-base.stickyNote",
      "n8n-nodes-base.stickyNote"
    ],
    "trigger": null
  }
}