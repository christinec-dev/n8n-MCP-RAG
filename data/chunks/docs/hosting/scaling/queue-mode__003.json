{
  "source": "docs/hosting/scaling/queue-mode.md",
  "index": 3,
  "content": "## How it works\n\nWhen running in queue mode, you have multiple n8n instances set up, with one main instance receiving workflow information (such as triggers) and the worker instances performing the executions. \n\nEach worker is its own Node.js instance, running in `main` mode, but able to handle multiple simultaneous workflow executions due to their high IOPS (input-output operations per second). \n\nBy using worker instances and running in queue mode, you can scale n8n up (by adding workers) and down (by removing workers) as needed to handle the workload.\n\nThis is the process flow:\n\n1. The main n8n instance handles timers and webhook calls, generating (but not running) a workflow execution. \n1. It passes the execution ID to a message broker, [Redis](#start-redis), which maintains the queue of pending executions and allows the next available worker to pick them up.\n1. A worker in the pool picks up message from Redis.\n1. The worker uses the execution ID to get workflow information from the database.\n1. After completing the workflow execution, the worker:\n\t- Writes the results to the database.\n\t- Posts to Redis, saying that the execution has finished.\n1. Redis notifies the main instance.\n\n\n![\"Diagram showing the flow of data between the main n8n instance, Redis, the n8n workers, and the n8n database\"](/_images/hosting/scaling/queue-mode-flow.png)"
}