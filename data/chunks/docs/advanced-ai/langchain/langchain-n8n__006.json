{
  "source": "docs/advanced-ai/langchain/langchain-n8n.md",
  "index": 6,
  "content": "### Sub-nodes\n\nEach root node can have one or more [sub-nodes](/glossary.md#sub-node-n8n) attached to it.\n\n#### Document loaders\n\nDocument loaders add data to your chain as documents. The data source can be a file or web service.\n\nAvailable nodes:\n\n* [Default Document Loader](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader.md)\n* [GitHub Document Loader](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentgithubloader.md)\n\nLearn more about [Document loaders in LangChain](https://js.langchain.com/docs/concepts/document_loaders).\n\n#### Language models\n\n[LLMs (large language models)](/glossary.md#large-language-model-llm) are programs that analyze datasets. They're the key element of working with AI.\n\nAvailable nodes:\n\n* [Anthropic Chat Model](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatanthropic.md)\n* [AWS Bedrock Chat Model](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatawsbedrock.md)\n* [Cohere Model](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmcohere.md)\n* [Hugging Face Inference Model](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmopenhuggingfaceinference.md)\n* [Mistral Cloud Chat Model](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatmistralcloud.md)\n* [Ollama Chat Model](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/index.md)\n* [Ollama Model](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmollama/index.md)\n* [OpenAI Chat Model](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatopenai/index.md)\n\nLearn more about [Language models in LangChain](https://js.langchain.com/docs/concepts/chat_models).\n\n#### Memory\n\n[Memory](/glossary.md#ai-memory) retains information about previous queries in a series of queries. For example, when a user interacts with a chat model, it's useful if your application can remember and call on the full conversation, not just the most recent query entered by the user.\n\nAvailable nodes:\n\n* [Motorhead](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorymotorhead.md)\n* [Redis Chat Memory](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memoryredischat.md)\n* [Postgres Chat Memory](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorypostgreschat.md) \n* [Simple Memory](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memorybufferwindow/index.md)\n* [Xata](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memoryxata.md)\n* [Zep](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.memoryzep.md)\n\nLearn more about [Memory in LangChain](https://langchain-ai.github.io/langgraphjs/concepts/memory/).\n\n#### Output parsers\n\nOutput parsers take the text generated by an LLM and format it to match the structure you require.\n\nAvailable nodes:\n\n* [Auto-fixing Output Parser](/integrations/builtin/"
}