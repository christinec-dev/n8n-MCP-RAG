{
  "source": "docs/advanced-ai/rag-in-n8n.md",
  "index": 6,
  "content": "### Inserting data into your vector store\n\nBefore your agent can access custom knowledge, you need to upload that data to a vector store:\n\n1. Add the nodes needed to fetch your source data.\n2. Insert a **Vector Store** node (e.g. the [Simple Vector Store](/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.vectorstoreinmemory.md)) and choose the **Insert Documents** operation.\n3. Select an **embedding model**, which converts your text into vector embeddings. Consult the FAQ for more information on [choosing the right embedding model](#how-do-i-choose-the-right-embedding-model).\n4. Add a [Default Data Loader](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader.md) node, which splits your content into chunks. You can use the default settings or define your own chunking strategy:\n\t* **Character Text Splitter:** splits by character length.\n\t* **Recursive Character Text Splitter:** recursively splits by Markdown, HTML, code blocks or simple characters (recommended for most use cases).\n\t* **Token Text Splitter:** splits by token count.\n5. (Optional) Add **metadata** to each chunk to enrich the context and allow better filtering later."
}