{
  "source": "docs/release-notes.md",
  "index": 37,
  "content": "### Support for RAG extended with built-in templates\n\nRetrieval-Augmented Generation (RAG) can improve AI responses by providing language models access to data sources with up-to-date, domain-specific, or proprietary knowledge. RAG workflows typically rely on vector stores to manage and search this data efficiently.\n\nTo get the benefits of using vector stores, such as returning results based on semantic meaning rather than just keyword matches, you need a way to upload your data to the vector store and a way to query it. \n\nIn n8n, uploading and querying vectors stores happens in two workflows. Now, you have an example to get your started and make implementation easier with the **RAG starter template**. \n\n- The **Load Data** workflow shows how to add data with the appropriate embedding model, split it into chunks with the [Default Data Loader](/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.documentdefaultdataloader.md), and add metadata as desired.\n- The **Retriever** workflow for querying data, shows how  agents and vector stores work together to help you define highly relevant results and save tokens using the **Question and Answer** tool.\n\nEnable semantic search and the retrieval of unstructured data  for increased quality and relevance of AI responses. \n\nüõ†Ô∏è **How to:** \n\n- Search for **RAG starter template** in the search bar of the Nodes panel to insert it into your workflow.\n\nLearn more about implementing RAG in n8n [here](/advanced-ai/rag-in-n8n.md).\n<br>\n<figure markdown=\"span\">\n    ![RAG starter template](/_images/release-notes/RAG_starter_template.png)\n    <figcaption>RAG starter template</figcaption>\n</figure>\n<br>\n\n\nFor full release details, refer to [Releases](https://github.com/n8n-io/n8n/releases) on GitHub."
}