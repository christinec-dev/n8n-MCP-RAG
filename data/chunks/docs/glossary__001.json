{
  "source": "docs/glossary.md",
  "index": 1,
  "content": "---\n#https://www.notion.so/n8n/Frontmatter-432c2b8dff1f43d4b1c8d20075510fe4\ntitle: n8n Glossary\ndescription: A glossary of terms commonly used when working with n8n and related software.\ncontentType: reference\n---\n\n#### AI agent\n\nAI agents are artificial intelligence systems capable of responding to requests, making decisions, and performing real-world tasks for users. They use large language models (LLMs) to interpret user input and make decisions about how to best process requests using the information and resources they have available.\n\n#### AI chain\n\nAI chains allow you to interact with large language models (LLMs) and other resources in sequences of calls to components. AI chains in n8n don't use persistent memory, so you can't use them to reference previous context (use AI agents for this).\n\n#### AI embedding\n\nEmbeddings are numerical representations of data using vectors. They're used by AI to interpret complex data and relationships by mapping values across many dimensions. Vector databases, or vector stores, are databases designed to store and access embeddings.\n\n#### AI groundedness\n\nIn AI, and specifically in retrieval-augmented generation (RAG) contexts, groundedness and ungroundedness are measures of how much a model's responses accurately reflect source information. The model uses its source documents to generate grounded responses, while ungrounded responses involve speculation or hallucination unsupported by those same sources.\n\n#### AI reranking\n\nReranking is a technique that refines the order of a list of candidate documents to improve the relevance of search results. Retrieval-Augmented Generation (RAG) and other applications use reranking to prioritize the most relevant information for generation or downstream tasks.\n\n#### AI memory\n\nIn an AI context, memory allows AI tools to persist message context across interactions. This allows you to have a continuing conversations with AI agents, for example, without submitting ongoing context with each message. In n8n, AI agent nodes can use memory, but AI chains can't.\n\n#### AI retrieval-augmented generation (RAG)\n\nRetrieval-augmented generation, or RAG, is a technique for providing LLMs access to new information from external sources to improve AI responses. RAG systems retrieve relevant documents to ground responses in up-to-date, domain-specific, or proprietary knowledge to supplement their original training data. RAG systems often rely on vector stores to manage and search this external data efficiently.\n\n#### AI tool\n\nIn an AI context, a tool is an add-on resource that the AI can refer to for specific information or functionality when responding to a request. The AI model can use a tool to interact with external systems or complete specific, focused tasks.\n\n#### AI vector store\n\nVector stores, or vector databases, are databases designed to store numerical representations of information called embeddings.\n\n#### API\n\nAPIs, or application programming interfaces, offer programmatic access to a service's data and functionality. APIs make it easier for software to interact with external systems. They're often offered as an alternative to traditional user-focused interfaces accessed through web browsers or UI.\n\n#### canvas (n8n)\n\nThe canvas is the main interface for building workflows in n8n's editor UI. You use the canvas to add and connect nodes to compose workflows.\n\n#### cluster node (n8n)\n\nIn n8n, cluster nodes are groups of nodes that work together to provide functionality in a workflow. They consist of a root node and one or more sub nodes that extend the node's functionality.\n\n#### credential (n8n)\n\nIn n8n, credentials store authentication information to connect with specific apps and services. After creating credentials with your authentication information (username and password, API key, OAuth secrets, etc.), you can use the associated app node to interact with the service.\n\n#### data pinning (n8n)\n\nData pinning allows you to temporarily freeze the output data of"
}