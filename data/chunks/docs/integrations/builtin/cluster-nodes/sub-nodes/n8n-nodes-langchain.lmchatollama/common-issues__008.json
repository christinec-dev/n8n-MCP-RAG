{
  "source": "docs/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatollama/common-issues.md",
  "index": 8,
  "content": "### If Ollama and n8n are running in separate Docker containers\n\nIf both n8n and Ollama are running in Docker in separate containers, you can use Docker networking to connect them.\n\nConfigure Ollama to listen on all interfaces by binding to `0.0.0.0` inside of the container (the official images are already configured this way).\n\nWhen configuring [Ollama credentials](/integrations/builtin/credentials/ollama.md), use the Ollama container's name as the host address instead of `localhost`. For example, if you call the Ollama container `my-ollama` and it listens on the default port 11434, you would set the base URL to `http://my-ollama:11434`."
}